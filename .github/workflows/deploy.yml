name: Deploy to Server

on:
  push:
    branches:
      - brutalist

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      # Step 1: Checkout the latest code from the repository
      - name: Checkout code
        uses: actions/checkout@v4

      # Step 2: Set up Node.js environment
      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18.19.1' # Use the same Node.js version as your server (v18.19.1)

      # Step 3: Install dependencies
      - name: Install dependencies
        run: npm install

      # Step 4: Setup SSH
      - name: Setup SSH
        uses: webfactory/ssh-agent@v0.7.0
        with:
          ssh-private-key: ${{ secrets.SFTP_PRIVATE_KEY }}

      # Step 5: Add host key
      - name: Add host key
        run: |
          mkdir -p ~/.ssh
          ssh-keyscan -H ${{ secrets.SFTP_HOST }} >> ~/.ssh/known_hosts

      # Step 6: Deploy to DigitalOcean
      - name: Deploy to DigitalOcean
        env:
          DROPLET_IP: ${{ secrets.SFTP_HOST }}
          DROPLET_USER: ${{ secrets.SFTP_USERNAME }}
          DEPLOY_PATH: "/root/portfolioServer"
          EMAIL: ${{ secrets.EMAIL }}
        run: |
          # Emergency disk space cleanup - server is full!
          ssh $DROPLET_USER@$DROPLET_IP "sudo rm -rf /tmp/* /var/tmp/*" || echo "Temp cleanup failed"
          ssh $DROPLET_USER@$DROPLET_IP "sudo journalctl --vacuum-time=1d" || echo "Journal cleanup failed"
          ssh $DROPLET_USER@$DROPLET_IP "sudo rm -rf /var/log/*.log.* /var/log/*/*.log.*" || echo "Log cleanup failed"
          ssh $DROPLET_USER@$DROPLET_IP "sudo rm -rf $DEPLOY_PATH/node_modules $DEPLOY_PATH/public $DEPLOY_PATH/views" || echo "Old deployment cleanup failed"
          ssh $DROPLET_USER@$DROPLET_IP "sudo apt-get clean" || echo "APT clean failed"
          ssh $DROPLET_USER@$DROPLET_IP "sudo find /var/cache -type f -delete" || echo "Cache cleanup failed"

          # Create deploy directory structure with proper permissions
          ssh $DROPLET_USER@$DROPLET_IP "sudo mkdir -p $DEPLOY_PATH && sudo chown -R $DROPLET_USER:$DROPLET_USER $DEPLOY_PATH"

          # Test SSH connection and check server prerequisites
          ssh $DROPLET_USER@$DROPLET_IP "echo 'SSH connection successful' && whoami && pwd"
          ssh $DROPLET_USER@$DROPLET_IP "df -h"  # Check disk space after cleanup
          ssh $DROPLET_USER@$DROPLET_IP "sudo du -sh /* 2>/dev/null | sort -hr | head -10" || echo "Disk usage check failed"
          ssh $DROPLET_USER@$DROPLET_IP "ls -la $DEPLOY_PATH || echo 'Deploy path does not exist yet'"
          ssh $DROPLET_USER@$DROPLET_IP "which node || echo 'Node.js not found'"
          ssh $DROPLET_USER@$DROPLET_IP "which npm || echo 'npm not found'"

          # Copy essential files first (excluding large images)
          echo "Copying essential files to $DEPLOY_PATH..."
          rsync -avz --progress --exclude='node_modules' --exclude='.git' --exclude='.DS_Store' --exclude='public/assets/img/portfolio/*.JPEG' --exclude='public/assets/img/portfolio/*.png' --delete package.json package-lock.json server.js views/ routes/ deploy.sh setup_https.sh portfolio.service $DROPLET_USER@$DROPLET_IP:$DEPLOY_PATH/ || {
            echo "Essential files rsync failed, trying scp..."
            scp -r package.json package-lock.json server.js views/ routes/ deploy.sh setup_https.sh portfolio.service $DROPLET_USER@$DROPLET_IP:$DEPLOY_PATH/
          }
          
          # Copy public assets (excluding large portfolio images for now)
          echo "Copying public assets (excluding large portfolio images)..."
          rsync -avz --progress --exclude='assets/img/portfolio/*.JPEG' --exclude='assets/img/portfolio/*.png' public/ $DROPLET_USER@$DROPLET_IP:$DEPLOY_PATH/public/ || echo "Public assets copy failed"

          # Make scripts executable
          ssh $DROPLET_USER@$DROPLET_IP "chmod +x $DEPLOY_PATH/deploy.sh $DEPLOY_PATH/setup_https.sh"

          # Run deployment script on server
          ssh $DROPLET_USER@$DROPLET_IP "cd $DEPLOY_PATH && bash deploy.sh"

          # Set up HTTPS (requires sudo)
          ssh $DROPLET_USER@$DROPLET_IP "cd $DEPLOY_PATH && sed -i 's/EMAIL=.*/EMAIL=\"$EMAIL\"/' setup_https.sh"
          ssh $DROPLET_USER@$DROPLET_IP "cd $DEPLOY_PATH && echo \"Setting up HTTPS requires sudo. If it doesn't work automatically, run 'sudo bash setup_https.sh' manually on the server.\""
          ssh $DROPLET_USER@$DROPLET_IP "cd $DEPLOY_PATH && sudo -n bash setup_https.sh || echo 'Please run setup_https.sh manually with sudo permissions'"

          
      # Step 7: Verify deployment
      - name: Verify deployment
        env:
          DROPLET_IP: ${{ secrets.SFTP_HOST }}
          DROPLET_USER: ${{ secrets.SFTP_USERNAME }}
          PRIMARY_DOMAIN: "enockmecheo.com"
          WWW_DOMAIN: "www.enockmecheo.com"
        run: |
          # Wait for service to start
          sleep 10
          # Check if service is running
          ssh $DROPLET_USER@$DROPLET_IP "systemctl is-active portfolio.service || echo 'Service not running'"
          echo "Deployment complete! Your application should be available at:"
          echo "  http://$DROPLET_IP"
          echo "  https://$PRIMARY_DOMAIN (if HTTPS setup completed successfully)"
          echo "  https://$WWW_DOMAIN (if HTTPS setup completed successfully)"